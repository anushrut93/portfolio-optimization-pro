{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Analysis Deep Dive - \n",
    "\n",
    "This notebook provides comprehensive analysis of portfolio backtesting, including:\n",
    "- Walk-forward optimization\n",
    "- Transaction cost analysis\n",
    "- Rebalancing frequency optimization\n",
    " - Monte Carlo simulation for strategy robustness\n",
    "- Optimal rebalancing frequency analysis\n",
    "- Strategy stability over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data.fetcher import DataFetcher\n",
    "from src.optimization.mean_variance import MeanVarianceOptimizer\n",
    "from src.backtesting.engine import BacktestEngine, BacktestConfig, RebalanceFrequency\n",
    "\n",
    "# Suppress verbose logging from all modules\n",
    "import logging\n",
    "\n",
    "# Set logging level for optimization module\n",
    "logging.getLogger('src.optimization.mean_variance').setLevel(logging.WARNING)\n",
    "logging.getLogger('src.optimization').setLevel(logging.WARNING)\n",
    "\n",
    "# Also suppress any root logger messages\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data\n",
    "tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'JPM']\n",
    "fetcher = DataFetcher()\n",
    "\n",
    "# Fetch longer history for robust backtesting\n",
    "prices = fetcher.fetch_price_data(\n",
    "    tickers=tickers,\n",
    "    start_date='2015-01-01',\n",
    "    end_date='2024-01-01'\n",
    ")\n",
    "\n",
    "print(f\"Data shape: {prices.shape}\")\n",
    "print(f\"Date range: {prices.index[0]} to {prices.index[-1]}\")\n",
    "\n",
    "# Calculate returns\n",
    "returns = prices.pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.5: Load ML Predictions from ML Notebook\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING ML PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if ML results exist\n",
    "ml_results_path = '../data/ml_results/ml_predictions.json'\n",
    "\n",
    "if os.path.exists(ml_results_path):\n",
    "    # Load ML predictions\n",
    "    with open(ml_results_path, 'r') as f:\n",
    "        ml_results = json.load(f)\n",
    "    \n",
    "    print(\"✓ Successfully loaded ML predictions\")\n",
    "    print(f\"  Created: {ml_results['metadata']['created_date']}\")\n",
    "    print(f\"  Data end date: {ml_results['metadata']['data_end_date']}\")\n",
    "    print(f\"  Blend ratio: {ml_results['metadata']['blend_ratio']}\")\n",
    "    \n",
    "    # Extract key components\n",
    "    ml_expected_returns = ml_results['ml_expected_returns']\n",
    "    ml_optimal_weights = ml_results['optimal_weights']['ml_enhanced']\n",
    "    ml_blend_ratio = ml_results['metadata']['blend_ratio']\n",
    "    \n",
    "    # Display ML predictions\n",
    "    print(\"\\nML Expected Returns (Annualized):\")\n",
    "    for ticker, ret in ml_expected_returns.items():\n",
    "        historical = ml_results['historical_baseline'].get(ticker, 0)\n",
    "        print(f\"  {ticker}: {ret:.1%} (Historical: {historical:.1%})\")\n",
    "    \n",
    "    # Performance improvement from ML\n",
    "    print(f\"\\nML Performance Improvement:\")\n",
    "    print(f\"  Traditional Sharpe: {ml_results['model_performance']['traditional_sharpe']:.3f}\")\n",
    "    print(f\"  ML-Enhanced Sharpe: {ml_results['model_performance']['ml_enhanced_sharpe']:.3f}\")\n",
    "    print(f\"  Improvement: {ml_results['model_performance']['improvement_pct']:.1f}%\")\n",
    "    \n",
    "    # Walk-forward validation stats\n",
    "    print(f\"\\nWalk-Forward Validation:\")\n",
    "    print(f\"  Periods tested: {ml_results['walk_forward_stats']['periods_tested']}\")\n",
    "    print(f\"  Success rate: {ml_results['walk_forward_stats']['success_rate']*100:.0f}%\")\n",
    "    print(f\"  Average Sharpe: {ml_results['walk_forward_stats']['average_sharpe']:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️  ML predictions not found!\")\n",
    "    print(f\"   Expected location: {ml_results_path}\")\n",
    "    print(\"   Please run the ML notebook (06_ml_price_prediction.ipynb) first.\")\n",
    "    print(\"\\n   Using default values for demonstration...\")\n",
    "    \n",
    "    # Fallback to reasonable defaults if ML results don't exist\n",
    "    ml_expected_returns = {\n",
    "        'AAPL': 0.15,\n",
    "        'MSFT': 0.12,\n",
    "        'GOOGL': 0.14,\n",
    "        'AMZN': 0.16,\n",
    "        'JPM': 0.10\n",
    "    }\n",
    "    ml_blend_ratio = 0.6\n",
    "    ml_optimal_weights = {ticker: 0.2 for ticker in tickers}\n",
    "\n",
    "# Verify tickers match\n",
    "ml_tickers = set(ml_expected_returns.keys())\n",
    "data_tickers = set(tickers)\n",
    "\n",
    "if ml_tickers != data_tickers:\n",
    "    print(f\"\\n⚠️  Warning: Ticker mismatch!\")\n",
    "    print(f\"   ML tickers: {ml_tickers}\")\n",
    "    print(f\"   Data tickers: {data_tickers}\")\n",
    "    \n",
    "    # Handle GOOG vs GOOGL mismatch if present\n",
    "    if 'GOOG' in data_tickers and 'GOOGL' in ml_tickers:\n",
    "        print(\"   Mapping GOOGL predictions to GOOG...\")\n",
    "        ml_expected_returns['GOOG'] = ml_expected_returns.get('GOOGL', 0.12)\n",
    "        if 'GOOG' not in ml_optimal_weights and 'GOOGL' in ml_optimal_weights:\n",
    "            ml_optimal_weights['GOOG'] = ml_optimal_weights['GOOGL']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2.6: Debug ML Data Loading\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DEBUGGING ML DATA LOADING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if the file exists\n",
    "import os\n",
    "ml_results_path = '../data/ml_results/ml_predictions.json'\n",
    "print(f\"1. Checking file existence:\")\n",
    "print(f\"   Path: {ml_results_path}\")\n",
    "print(f\"   Exists: {os.path.exists(ml_results_path)}\")\n",
    "\n",
    "if os.path.exists(ml_results_path):\n",
    "    # Check file contents\n",
    "    print(f\"\\n2. File info:\")\n",
    "    print(f\"   Size: {os.path.getsize(ml_results_path)} bytes\")\n",
    "    print(f\"   Modified: {pd.Timestamp.fromtimestamp(os.path.getmtime(ml_results_path))}\")\n",
    "    \n",
    "    # Load and display raw contents\n",
    "    import json\n",
    "    with open(ml_results_path, 'r') as f:\n",
    "        raw_data = json.load(f)\n",
    "    \n",
    "    print(f\"\\n3. File contents - ML predictions:\")\n",
    "    if 'ml_expected_returns' in raw_data:\n",
    "        for ticker, value in raw_data['ml_expected_returns'].items():\n",
    "            print(f\"   {ticker}: {value:.4f} ({value*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"   ERROR: 'ml_expected_returns' key not found!\")\n",
    "        print(\"   Available keys:\", list(raw_data.keys()))\n",
    "    \n",
    "    print(f\"\\n4. Currently loaded values:\")\n",
    "    for ticker, value in ml_expected_returns.items():\n",
    "        print(f\"   {ticker}: {value:.4f} ({value*100:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n⚠️  FILE NOT FOUND! Using fallback values.\")\n",
    "    print(\"   This explains why you're seeing hardcoded values!\")\n",
    "    print(\"\\n   Next steps:\")\n",
    "    print(\"   1. Run the ML notebook (06_ml_price_prediction.ipynb)\")\n",
    "    print(\"   2. Make sure to run the export cell (Cell 10)\")\n",
    "    print(\"   3. Check that the file is created in ../data/ml_results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Walk-Forward Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_backtest(\n",
    "    prices, \n",
    "    lookback_period=252,  # 1 year\n",
    "    rebalance_frequency='monthly',\n",
    "    optimization_method='max_sharpe'\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform walk-forward backtesting\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    portfolio_values = [100000]  # Starting capital\n",
    "    weights_history = []\n",
    "    \n",
    "    # Set up rebalancing dates\n",
    "    if rebalance_frequency == 'monthly':\n",
    "        rebalance_dates = pd.date_range(\n",
    "            start=prices.index[lookback_period],\n",
    "            end=prices.index[-1],\n",
    "            freq='MS'  # Month start\n",
    "        )\n",
    "    elif rebalance_frequency == 'quarterly':\n",
    "        rebalance_dates = pd.date_range(\n",
    "            start=prices.index[lookback_period],\n",
    "            end=prices.index[-1],\n",
    "            freq='QS'  # Quarter start\n",
    "        )\n",
    "    \n",
    "    optimizer = MeanVarianceOptimizer()\n",
    "    current_weights = None\n",
    "    \n",
    "    for i, date in enumerate(prices.index[lookback_period:]):\n",
    "        # Check if we need to rebalance\n",
    "        if date in rebalance_dates:\n",
    "            # Get historical data for optimization\n",
    "            historical_prices = prices.loc[:date].tail(lookback_period)\n",
    "            \n",
    "            # Optimize portfolio\n",
    "            result = optimizer.optimize(\n",
    "                historical_prices,\n",
    "                objective=optimization_method\n",
    "            )\n",
    "            \n",
    "            current_weights = pd.Series(\n",
    "                result.weights,\n",
    "                index=result.asset_names\n",
    "            )\n",
    "            weights_history.append({\n",
    "                'date': date,\n",
    "                'weights': current_weights.to_dict()\n",
    "            })\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        if current_weights is not None:\n",
    "            # Calculate returns\n",
    "            if i > 0:\n",
    "                daily_returns = prices.loc[date] / prices.iloc[lookback_period + i - 1] - 1\n",
    "                portfolio_return = (current_weights * daily_returns).sum()\n",
    "                portfolio_values.append(portfolio_values[-1] * (1 + portfolio_return))\n",
    "            \n",
    "            results.append({\n",
    "                'date': date,\n",
    "                'portfolio_value': portfolio_values[-1] if i > 0 else portfolio_values[0],\n",
    "                'weights': current_weights.to_dict()\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results), pd.DataFrame(weights_history)\n",
    "\n",
    "# Run walk-forward backtest\n",
    "print(\"Running walk-forward backtest...\")\n",
    "backtest_results, weights_history = walk_forward_backtest(\n",
    "    prices,\n",
    "    lookback_period=252,\n",
    "    rebalance_frequency='monthly',\n",
    "    optimization_method='max_sharpe'\n",
    ")\n",
    "\n",
    "# Calculate performance metrics\n",
    "final_value = backtest_results['portfolio_value'].iloc[-1]\n",
    "total_return = (final_value / 100000 - 1) * 100\n",
    "years = len(backtest_results) / 252\n",
    "annual_return = (final_value / 100000) ** (1/years) - 1\n",
    "\n",
    "print(f\"\\nWalk-Forward Backtest Results:\")\n",
    "print(f\"Final Portfolio Value: ${final_value:,.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Annualized Return: {annual_return:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transaction Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_with_costs(prices, initial_weights, rebalance_freq, transaction_cost):\n",
    "    \"\"\"\n",
    "    Run backtest with different transaction costs\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    original_level = logging.getLogger().level\n",
    "    logging.getLogger().setLevel(logging.WARNING)\n",
    "    config = BacktestConfig(\n",
    "        initial_capital=100000,\n",
    "        transaction_cost_pct=transaction_cost,\n",
    "        rebalance_frequency=rebalance_freq\n",
    "    )\n",
    "    \n",
    "    engine = BacktestEngine(config)\n",
    "    \n",
    "    # Create strategy that returns fixed weights\n",
    "    def fixed_weight_strategy(historical_prices):\n",
    "        return initial_weights\n",
    "    \n",
    "    results = engine.run_backtest(prices, fixed_weight_strategy)\n",
    "    return results\n",
    "\n",
    "# Test different transaction costs\n",
    "transaction_costs = [0, 0.001, 0.002, 0.005, 0.01]  # 0 to 1%\n",
    "rebalance_frequencies = [\n",
    "    RebalanceFrequency.DAILY,\n",
    "    RebalanceFrequency.WEEKLY,\n",
    "    RebalanceFrequency.MONTHLY,\n",
    "    RebalanceFrequency.QUARTERLY\n",
    "]\n",
    "\n",
    "# Use equal weights for comparison\n",
    "equal_weights = np.array([0.2] * 5)\n",
    "\n",
    "# Store results\n",
    "cost_analysis_results = {}\n",
    "\n",
    "for freq in rebalance_frequencies:\n",
    "    cost_analysis_results[freq.value] = {}\n",
    "    \n",
    "    for cost in transaction_costs:\n",
    "        results = backtest_with_costs(\n",
    "            prices.tail(252*3),  # Last 2 years\n",
    "            equal_weights,\n",
    "            freq,\n",
    "            cost\n",
    "        )\n",
    "        \n",
    "        final_value = results.portfolio_values.iloc[-1]\n",
    "        total_return = (final_value / 100000 - 1)\n",
    "        \n",
    "        cost_analysis_results[freq.value][cost] = {\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'total_costs': results.total_transaction_costs + results.total_slippage_costs,\n",
    "            'turnover': results.turnover_rate\n",
    "        }\n",
    "\n",
    "# Create visualization\n",
    "fig = go.Figure()\n",
    "\n",
    "for freq in rebalance_frequencies:\n",
    "    returns = [cost_analysis_results[freq.value][cost]['total_return'] * 100 \n",
    "               for cost in transaction_costs]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[c * 100 for c in transaction_costs],\n",
    "        y=returns,\n",
    "        mode='lines+markers',\n",
    "        name=freq.value.capitalize(),\n",
    "        line=dict(width=2)\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Impact of Transaction Costs on Returns by Rebalancing Frequency',\n",
    "    xaxis_title='Transaction Cost (%)',\n",
    "    yaxis_title='Total Return (%)',\n",
    "    hovermode='x unified',\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Turnover analysis\n",
    "print(\"\\nPortfolio Turnover by Rebalancing Frequency:\")\n",
    "for freq in rebalance_frequencies:\n",
    "    turnover = cost_analysis_results[freq.value][0.001]['turnover']\n",
    "    print(f\"{freq.value.capitalize()}: {turnover:.1%} annual turnover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing Strategies Across Market Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define market periods\n",
    "market_periods = {\n",
    "    'Bull Market (2017-2019)': ('2017-01-01', '2019-12-31'),\n",
    "    'COVID Crash (2020)': ('2020-01-01', '2020-12-31'),\n",
    "    'Recovery (2021-2022)': ('2021-01-01', '2022-12-31'),\n",
    "    'Recent (2023)': ('2023-01-01', '2023-12-31')\n",
    "}\n",
    "\n",
    "# Strategies to test\n",
    "strategies_to_test = {\n",
    "    'max_sharpe': 'Max Sharpe',\n",
    "    'min_volatility': 'Min Volatility'\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "period_results = {}\n",
    "\n",
    "for period_name, (start, end) in market_periods.items():\n",
    "    period_results[period_name] = {}\n",
    "    \n",
    "    # Get data for this period\n",
    "    period_prices = prices[start:end]\n",
    "    \n",
    "    if len(period_prices) < 20:  # Skip if too few data points\n",
    "        continue\n",
    "    \n",
    "    # Optimize at the beginning of the period\n",
    "    train_end = period_prices.index[0] - timedelta(days=1)\n",
    "    train_start = train_end - timedelta(days=365)\n",
    "    train_prices = prices[train_start:train_end]\n",
    "    \n",
    "    optimizer = MeanVarianceOptimizer()\n",
    "    \n",
    "    for strategy_key, strategy_name in strategies_to_test.items():\n",
    "        # Optimize\n",
    "        result = optimizer.optimize(train_prices, objective=strategy_key)\n",
    "        weights = pd.Series(result.weights, index=result.asset_names)\n",
    "        \n",
    "        # Calculate performance\n",
    "        period_returns = period_prices.pct_change().dropna()\n",
    "        portfolio_returns = (period_returns * weights).sum(axis=1)\n",
    "        \n",
    "        cumulative_return = (1 + portfolio_returns).cumprod()\n",
    "        total_return = cumulative_return.iloc[-1] - 1\n",
    "        volatility = portfolio_returns.std() * np.sqrt(252)\n",
    "        sharpe = (portfolio_returns.mean() * 252 - 0.02) / volatility\n",
    "        \n",
    "        # Calculate max drawdown\n",
    "        running_max = cumulative_return.expanding().max()\n",
    "        drawdown = (cumulative_return - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        period_results[period_name][strategy_name] = {\n",
    "            'return': total_return,\n",
    "            'volatility': volatility,\n",
    "            'sharpe': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'cumulative': cumulative_return\n",
    "        }\n",
    "\n",
    "# Create comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=list(market_periods.keys()),\n",
    "    shared_yaxes=True\n",
    ")\n",
    "\n",
    "colors = {'Max Sharpe': 'blue', 'Min Volatility': 'green'}\n",
    "\n",
    "for i, (period_name, results) in enumerate(period_results.items()):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    \n",
    "    for strategy_name, metrics in results.items():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=metrics['cumulative'].index,\n",
    "                y=(metrics['cumulative'] - 1) * 100,\n",
    "                mode='lines',\n",
    "                name=strategy_name,\n",
    "                line=dict(color=colors[strategy_name], width=2),\n",
    "                showlegend=(i == 0)  # Only show legend once\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "fig.update_yaxes(title_text='Cumulative Return (%)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Cumulative Return (%)', row=2, col=1)\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    title_text='Strategy Performance Across Market Conditions',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nPerformance Summary by Period:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for period_name, results in period_results.items():\n",
    "    print(f\"\\n{period_name}:\")\n",
    "    for strategy_name, metrics in results.items():\n",
    "        print(f\"  {strategy_name}:\")\n",
    "        print(f\"    Return: {metrics['return']:.2%}\")\n",
    "        print(f\"    Volatility: {metrics['volatility']:.2%}\")\n",
    "        print(f\"    Sharpe: {metrics['sharpe']:.3f}\")\n",
    "        print(f\"    Max Drawdown: {metrics['max_drawdown']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monte Carlo Simulation for Strategy Robustness## 5. Monte Carlo Simulation for Strategy Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 6: Monte Carlo Simulation for Strategy Robustness\n",
    "\n",
    "# Define the ML strategy creation function here so it's available for Monte Carlo\n",
    "def create_ml_enhanced_strategy(ml_predictions, ml_blend_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Creates a strategy function that uses loaded ML predictions\n",
    "    blended with historical returns\n",
    "    \"\"\"\n",
    "    def ml_enhanced_strategy(historical_prices):\n",
    "        \"\"\"\n",
    "        Strategy that combines ML predictions with dynamic historical data\n",
    "        \"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # Calculate historical statistics from the provided data\n",
    "        returns = historical_prices.pct_change().dropna()\n",
    "        historical_mean = returns.mean() * 252\n",
    "        historical_cov = returns.cov() * 252\n",
    "        \n",
    "        # Convert ML predictions to Series aligned with historical data\n",
    "        ml_returns = pd.Series(\n",
    "            index=historical_prices.columns,\n",
    "            dtype=float\n",
    "        )\n",
    "        \n",
    "        # Map ML predictions to the correct tickers\n",
    "        for ticker in historical_prices.columns:\n",
    "            if ticker in ml_predictions:\n",
    "                ml_returns[ticker] = ml_predictions[ticker]\n",
    "            elif ticker == 'GOOG' and 'GOOGL' in ml_predictions:\n",
    "                ml_returns[ticker] = ml_predictions['GOOGL']\n",
    "            else:\n",
    "                ml_returns[ticker] = historical_mean[ticker]\n",
    "        \n",
    "        # Blend ML predictions with historical returns\n",
    "        blended_returns = ml_blend_ratio * ml_returns + (1 - ml_blend_ratio) * historical_mean\n",
    "        \n",
    "        # Optimize portfolio with blended returns\n",
    "        n_assets = len(blended_returns)\n",
    "        \n",
    "        def objective(w):\n",
    "            port_return = np.dot(w, blended_returns)\n",
    "            port_vol = np.sqrt(np.dot(w.T, np.dot(historical_cov.values, w)))\n",
    "            sharpe = (port_return - 0.02) / port_vol\n",
    "            return -sharpe  # Negative for minimization\n",
    "        \n",
    "        # Constraints and bounds\n",
    "        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "        bounds = tuple((0.05, 0.40) for _ in range(n_assets))\n",
    "        x0 = np.ones(n_assets) / n_assets\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(objective, x0, method='SLSQP', \n",
    "                         bounds=bounds, constraints=constraints,\n",
    "                         options={'ftol': 1e-9, 'disp': False})\n",
    "        \n",
    "        if not result.success:\n",
    "            return x0  # Return equal weights if optimization fails\n",
    "        \n",
    "        return result.x\n",
    "    \n",
    "    return ml_enhanced_strategy\n",
    "\n",
    "# Now continue with the Monte Carlo simulation\n",
    "def monte_carlo_backtest(prices, n_simulations=1000, test_period_days=252, \n",
    "                        ml_predictions=None, ml_blend_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulations to test strategy robustness\n",
    "    Now includes ML-enhanced strategy testing\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Create ML strategy if predictions provided\n",
    "    if ml_predictions is not None:\n",
    "        ml_strategy = create_ml_enhanced_strategy(ml_predictions, ml_blend_ratio)\n",
    "    \n",
    "    for sim in range(n_simulations):\n",
    "        # Randomly select training period\n",
    "        max_start = len(prices) - test_period_days - 252  # Need 1 year for training\n",
    "        start_idx = np.random.randint(252, max_start)\n",
    "        \n",
    "        # Split data\n",
    "        train_prices = prices.iloc[start_idx-252:start_idx]\n",
    "        test_prices = prices.iloc[start_idx:start_idx+test_period_days]\n",
    "        \n",
    "        # Test both traditional and ML strategies\n",
    "        strategies = {\n",
    "            'traditional': 'max_sharpe',\n",
    "            'ml_enhanced': ml_strategy if ml_predictions is not None else None\n",
    "        }\n",
    "        \n",
    "        for strategy_name, strategy in strategies.items():\n",
    "            if strategy is None:\n",
    "                continue\n",
    "                \n",
    "            if strategy_name == 'traditional':\n",
    "                # Traditional optimization\n",
    "                optimizer = MeanVarianceOptimizer()\n",
    "                result = optimizer.optimize(train_prices, objective=strategy)\n",
    "                weights = pd.Series(result.weights, index=result.asset_names)\n",
    "            else:\n",
    "                # ML-enhanced strategy\n",
    "                weights = pd.Series(strategy(train_prices), index=train_prices.columns)\n",
    "            \n",
    "            # Test on out-of-sample data\n",
    "            test_returns = test_prices.pct_change().dropna()\n",
    "            portfolio_returns = (test_returns * weights).sum(axis=1)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            total_return = (1 + portfolio_returns).prod() - 1\n",
    "            annual_return = (1 + total_return) ** (252/len(portfolio_returns)) - 1\n",
    "            volatility = portfolio_returns.std() * np.sqrt(252)\n",
    "            sharpe = (annual_return - 0.02) / volatility if volatility > 0 else 0\n",
    "            \n",
    "            # Calculate max drawdown\n",
    "            cum_returns = (1 + portfolio_returns).cumprod()\n",
    "            running_max = cum_returns.expanding().max()\n",
    "            drawdown = (cum_returns - running_max) / running_max\n",
    "            max_drawdown = drawdown.min()\n",
    "            \n",
    "            results.append({\n",
    "                'simulation': sim,\n",
    "                'strategy': strategy_name,\n",
    "                'train_start': prices.index[start_idx-252],\n",
    "                'test_start': prices.index[start_idx],\n",
    "                'annual_return': annual_return,\n",
    "                'volatility': volatility,\n",
    "                'sharpe_ratio': sharpe,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'total_return': total_return\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run Monte Carlo simulation with ML predictions\n",
    "print(\"Running Monte Carlo simulation with ML strategies (this may take a minute)...\")\n",
    "mc_results = monte_carlo_backtest(\n",
    "    prices, \n",
    "    n_simulations=500,  # Reduced for faster execution\n",
    "    ml_predictions=ml_expected_returns,\n",
    "    ml_blend_ratio=ml_blend_ratio\n",
    ")\n",
    "\n",
    "# Separate results by strategy\n",
    "traditional_results = mc_results[mc_results['strategy'] == 'traditional']\n",
    "ml_results = mc_results[mc_results['strategy'] == 'ml_enhanced']\n",
    "\n",
    "# Create comparative visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Sharpe Ratio Distribution', 'Annual Return Distribution', \n",
    "                   'Risk-Return Scatter (All Simulations)', 'Drawdown Comparison')\n",
    ")\n",
    "\n",
    "# 1. Sharpe ratio distributions\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=traditional_results['sharpe_ratio'], \n",
    "                 name='Traditional', opacity=0.7,\n",
    "                 marker_color='blue', nbinsx=30),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=ml_results['sharpe_ratio'], \n",
    "                 name='ML-Enhanced', opacity=0.7,\n",
    "                 marker_color='green', nbinsx=30),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Return distributions\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=traditional_results['annual_return'], \n",
    "                 name='Traditional', opacity=0.7,\n",
    "                 marker_color='blue', nbinsx=30, showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=ml_results['annual_return'], \n",
    "                 name='ML-Enhanced', opacity=0.7,\n",
    "                 marker_color='green', nbinsx=30, showlegend=False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Risk-return scatter\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=traditional_results['volatility'],\n",
    "        y=traditional_results['annual_return'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, opacity=0.5, color='blue'),\n",
    "        name='Traditional'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=ml_results['volatility'],\n",
    "        y=ml_results['annual_return'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, opacity=0.5, color='green'),\n",
    "        name='ML-Enhanced'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Drawdown comparison\n",
    "fig.add_trace(\n",
    "    go.Box(y=traditional_results['max_drawdown'], \n",
    "           name='Traditional', marker_color='blue'),\n",
    "    row=2, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Box(y=ml_results['max_drawdown'], \n",
    "           name='ML-Enhanced', marker_color='green'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(tickformat='.0%', row=2, col=1)\n",
    "fig.update_yaxes(tickformat='.0%', row=2, col=1)\n",
    "fig.update_yaxes(tickformat='.0%', row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, title_text='Monte Carlo Simulation: ML vs Traditional (500 runs)')\n",
    "fig.show()\n",
    "\n",
    "# Summary statistics comparison\n",
    "print(\"\\nMonte Carlo Simulation Summary:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate comparative statistics\n",
    "comparison_stats = pd.DataFrame({\n",
    "    'Traditional': [\n",
    "        traditional_results['annual_return'].mean(),\n",
    "        traditional_results['volatility'].mean(),\n",
    "        traditional_results['sharpe_ratio'].mean(),\n",
    "        traditional_results['max_drawdown'].mean(),\n",
    "        traditional_results['sharpe_ratio'].quantile(0.05),\n",
    "        (traditional_results['sharpe_ratio'] > 0).mean()\n",
    "    ],\n",
    "    'ML-Enhanced': [\n",
    "        ml_results['annual_return'].mean(),\n",
    "        ml_results['volatility'].mean(),\n",
    "        ml_results['sharpe_ratio'].mean(),\n",
    "        ml_results['max_drawdown'].mean(),\n",
    "        ml_results['sharpe_ratio'].quantile(0.05),\n",
    "        (ml_results['sharpe_ratio'] > 0).mean()\n",
    "    ]\n",
    "}, index=['Avg Annual Return', 'Avg Volatility', 'Avg Sharpe Ratio', \n",
    "          'Avg Max Drawdown', '5% VaR Sharpe', 'P(Sharpe > 0)'])\n",
    "\n",
    "# Format the comparison\n",
    "for col in comparison_stats.columns:\n",
    "    for idx in comparison_stats.index:\n",
    "        if 'Return' in idx or 'Volatility' in idx or 'Drawdown' in idx or 'P(' in idx:\n",
    "            comparison_stats.loc[idx, col] = f\"{comparison_stats.loc[idx, col]:.2%}\"\n",
    "        else:\n",
    "            comparison_stats.loc[idx, col] = f\"{comparison_stats.loc[idx, col]:.3f}\"\n",
    "\n",
    "print(comparison_stats)\n",
    "\n",
    "# Calculate win rate\n",
    "ml_wins = 0\n",
    "for sim in range(len(traditional_results)):\n",
    "    if ml_results.iloc[sim]['sharpe_ratio'] > traditional_results.iloc[sim]['sharpe_ratio']:\n",
    "        ml_wins += 1\n",
    "\n",
    "win_rate = ml_wins / len(traditional_results)\n",
    "print(f\"\\nML Win Rate: {win_rate:.1%} (ML outperforms Traditional)\")\n",
    "print(f\"Average Sharpe Improvement: {(ml_results['sharpe_ratio'].mean() - traditional_results['sharpe_ratio'].mean()):.3f}\")\n",
    "\n",
    "# Statistical significance test\n",
    "from scipy import stats\n",
    "t_stat, p_value = stats.ttest_rel(ml_results['sharpe_ratio'], traditional_results['sharpe_ratio'])\n",
    "print(f\"\\nPaired t-test: t={t_stat:.3f}, p-value={p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"✓ ML improvement is statistically significant at 5% level\")\n",
    "else:\n",
    "    print(\"✗ ML improvement is not statistically significant at 5% level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimal Rebalancing Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('src.optimization.mean_variance').setLevel(logging.ERROR)\n",
    "logging.getLogger('src.backtesting.engine').setLevel(logging.WARNING)\n",
    "\n",
    "# Test different rebalancing frequencies with realistic costs\n",
    "rebalance_analysis = {}\n",
    "transaction_cost = 0.001  # 0.1% realistic cost\n",
    "\n",
    "frequencies_to_test = [\n",
    "    ('Never', RebalanceFrequency.NEVER),\n",
    "    ('Yearly', RebalanceFrequency.YEARLY),\n",
    "    ('Quarterly', RebalanceFrequency.QUARTERLY),\n",
    "    ('Monthly', RebalanceFrequency.MONTHLY),\n",
    "    ('Weekly', RebalanceFrequency.WEEKLY),\n",
    "    ('Daily', RebalanceFrequency.DAILY)\n",
    "]\n",
    "\n",
    "# Get optimal weights from recent data\n",
    "recent_prices = prices.tail(252)\n",
    "optimizer = MeanVarianceOptimizer()\n",
    "result = optimizer.optimize(recent_prices, objective='max_sharpe')\n",
    "optimal_weights = result.weights\n",
    "\n",
    "# Test each frequency\n",
    "test_prices = prices.tail(252*3)  # Last 3 years\n",
    "\n",
    "for freq_name, freq_enum in frequencies_to_test:\n",
    "    config = BacktestConfig(\n",
    "        initial_capital=100000,\n",
    "        transaction_cost_pct=transaction_cost,\n",
    "        rebalance_frequency=freq_enum\n",
    "    )\n",
    "    \n",
    "    engine = BacktestEngine(config)\n",
    "    \n",
    "    # Strategy that returns optimal weights\n",
    "    def optimal_weight_strategy(historical_prices):\n",
    "        return optimal_weights\n",
    "    \n",
    "    results = engine.run_backtest(test_prices, optimal_weight_strategy)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    returns = results.returns\n",
    "    annual_return = returns.mean() * 252\n",
    "    volatility = returns.std() * np.sqrt(252)\n",
    "    sharpe = (annual_return - 0.02) / volatility if volatility > 0 else 0\n",
    "    \n",
    "    rebalance_analysis[freq_name] = {\n",
    "        'annual_return': annual_return,\n",
    "        'volatility': volatility,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'total_costs': results.total_transaction_costs,\n",
    "        'turnover': results.turnover_rate,\n",
    "        'final_value': results.portfolio_values.iloc[-1],\n",
    "        'trades': len(results.trades)\n",
    "    }\n",
    "\n",
    "# Create comparison chart\n",
    "rebalance_df = pd.DataFrame(rebalance_analysis).T\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Net Returns vs Costs', 'Sharpe Ratio', 'Turnover Rate', 'Number of Trades'),\n",
    "    specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
    "           [{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Net returns\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rebalance_df.index, y=rebalance_df['annual_return'] * 100, name='Annual Return'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Sharpe ratio\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rebalance_df.index, y=rebalance_df['sharpe_ratio'], name='Sharpe Ratio'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Turnover\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rebalance_df.index, y=rebalance_df['turnover'] * 100, name='Turnover %'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Number of trades\n",
    "fig.add_trace(\n",
    "    go.Bar(x=rebalance_df.index, y=rebalance_df['trades'], name='Trades'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text='Annual Return (%)', row=1, col=1)\n",
    "fig.update_yaxes(title_text='Sharpe Ratio', row=1, col=2)\n",
    "fig.update_yaxes(title_text='Annual Turnover (%)', row=2, col=1)\n",
    "fig.update_yaxes(title_text='Number of Trades', row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False, \n",
    "                  title_text='Rebalancing Frequency Analysis (with 0.1% transaction costs)')\n",
    "fig.show()\n",
    "\n",
    "# Print detailed analysis\n",
    "print(\"\\nRebalancing Frequency Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Frequency':<15} {'Return':<10} {'Sharpe':<10} {'Costs':<10} {'Turnover':<10} {'Final Value':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for freq, metrics in rebalance_analysis.items():\n",
    "    print(f\"{freq:<15} {metrics['annual_return']*100:>8.2f}% {metrics['sharpe_ratio']:>9.3f} \"\n",
    "          f\"${metrics['total_costs']:>8.0f} {metrics['turnover']*100:>8.1f}% ${metrics['final_value']:>14,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Strategy Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how stable the optimal weights are over time\n",
    "def analyze_weight_stability(prices, lookback=252, rebalance_freq='monthly'):\n",
    "    \"\"\"\n",
    "    Track how portfolio weights change over time\n",
    "    \"\"\"\n",
    "    optimizer = MeanVarianceOptimizer()\n",
    "    weight_history = []\n",
    "    \n",
    "    # Generate rebalance dates\n",
    "    if rebalance_freq == 'monthly':\n",
    "        dates = pd.date_range(start=prices.index[lookback], end=prices.index[-1], freq='MS')\n",
    "    else:\n",
    "        dates = pd.date_range(start=prices.index[lookback], end=prices.index[-1], freq='QS')\n",
    "    \n",
    "    for date in dates:\n",
    "        # Get historical data\n",
    "        # Find the closest date in the index\n",
    "        hist_end_idx = prices.index.get_indexer([date], method='nearest')[0]\n",
    "        hist_start_idx = hist_end_idx - lookback\n",
    "        \n",
    "        if hist_start_idx < 0:\n",
    "            continue\n",
    "            \n",
    "        hist_prices = prices.iloc[hist_start_idx:hist_end_idx]\n",
    "        \n",
    "        # Optimize\n",
    "        result = optimizer.optimize(hist_prices, objective='max_sharpe')\n",
    "        \n",
    "        weight_dict = {'date': date}\n",
    "        for asset, weight in zip(result.asset_names, result.weights):\n",
    "            weight_dict[asset] = weight\n",
    "            \n",
    "        weight_history.append(weight_dict)\n",
    "    \n",
    "    return pd.DataFrame(weight_history).set_index('date')\n",
    "\n",
    "# Analyze weight stability\n",
    "weight_history = analyze_weight_stability(prices, rebalance_freq='monthly')\n",
    "\n",
    "# Visualize weight evolution\n",
    "fig = go.Figure()\n",
    "\n",
    "for column in weight_history.columns:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=weight_history.index,\n",
    "        y=weight_history[column] * 100,\n",
    "        mode='lines',\n",
    "        name=column,\n",
    "        stackgroup='one'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Portfolio Weight Evolution Over Time',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Weight (%)',\n",
    "    hovermode='x unified',\n",
    "    height=500,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Calculate weight stability metrics\n",
    "weight_changes = weight_history.diff().abs()\n",
    "avg_change = weight_changes.mean()\n",
    "max_change = weight_changes.max()\n",
    "\n",
    "print(\"\\nWeight Stability Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Average Monthly Weight Change:\")\n",
    "for asset in avg_change.index:\n",
    "    print(f\"  {asset}: {avg_change[asset]*100:.2f}%\")\n",
    "    \n",
    "print(\"\\nMaximum Single-Month Weight Change:\")\n",
    "for asset in max_change.index:\n",
    "    print(f\"  {asset}: {max_change[asset]*100:.2f}%\")\n",
    "    \n",
    "print(f\"\\nTotal portfolio turnover per rebalance: {weight_changes.sum(axis=1).mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Weight Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: ML-Enhanced Strategy Backtesting\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ML-ENHANCED STRATEGY BACKTESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Import necessary optimization functions at module level\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_ml_enhanced_strategy(ml_predictions, ml_blend_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Creates a strategy function that uses loaded ML predictions\n",
    "    blended with historical returns\n",
    "    \"\"\"\n",
    "    def ml_enhanced_strategy(historical_prices):\n",
    "        \"\"\"\n",
    "        Strategy that combines ML predictions with dynamic historical data\n",
    "        \"\"\"\n",
    "        # Calculate historical statistics from the provided data\n",
    "        returns = historical_prices.pct_change().dropna()\n",
    "        historical_mean = returns.mean() * 252\n",
    "        historical_cov = returns.cov() * 252\n",
    "        \n",
    "        # Convert ML predictions to Series aligned with historical data\n",
    "        ml_returns = pd.Series(\n",
    "            index=historical_prices.columns,\n",
    "            dtype=float\n",
    "        )\n",
    "        \n",
    "        # Map ML predictions to the correct tickers\n",
    "        for ticker in historical_prices.columns:\n",
    "            if ticker in ml_predictions:\n",
    "                ml_returns[ticker] = ml_predictions[ticker]\n",
    "            elif ticker == 'GOOG' and 'GOOGL' in ml_predictions:\n",
    "                ml_returns[ticker] = ml_predictions['GOOGL']\n",
    "            else:\n",
    "                print(f\"Warning: No ML prediction for {ticker}, using historical\")\n",
    "                ml_returns[ticker] = historical_mean[ticker]\n",
    "        \n",
    "        # Blend ML predictions with historical returns\n",
    "        blended_returns = ml_blend_ratio * ml_returns + (1 - ml_blend_ratio) * historical_mean\n",
    "        \n",
    "        # Optimize portfolio with blended returns\n",
    "        n_assets = len(blended_returns)\n",
    "        \n",
    "        def objective(w):\n",
    "            port_return = np.dot(w, blended_returns)\n",
    "            port_vol = np.sqrt(np.dot(w.T, np.dot(historical_cov.values, w)))\n",
    "            sharpe = (port_return - 0.02) / port_vol\n",
    "            return -sharpe  # Negative for minimization\n",
    "        \n",
    "        # Constraints and bounds\n",
    "        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "        bounds = tuple((0.05, 0.40) for _ in range(n_assets))\n",
    "        x0 = np.ones(n_assets) / n_assets\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(objective, x0, method='SLSQP', \n",
    "                         bounds=bounds, constraints=constraints,\n",
    "                         options={'ftol': 1e-9, 'disp': False})\n",
    "        \n",
    "        if not result.success:\n",
    "            print(f\"Optimization warning: {result.message}\")\n",
    "            return x0  # Return equal weights if optimization fails\n",
    "        \n",
    "        return result.x\n",
    "    \n",
    "    return ml_enhanced_strategy\n",
    "\n",
    "# Create strategy using loaded ML predictions\n",
    "print(f\"\\nUsing ML predictions loaded from: {ml_results_path}\")\n",
    "print(f\"ML blend ratio: {ml_blend_ratio}\")\n",
    "\n",
    "# Define strategies to compare (EXCLUDING Equal Weight)\n",
    "strategies_to_compare = {\n",
    "    'Traditional Max Sharpe': lambda prices: MeanVarianceOptimizer().optimize(\n",
    "        prices, objective='max_sharpe').weights,\n",
    "    \n",
    "    'ML-Enhanced (Loaded)': create_ml_enhanced_strategy(\n",
    "        ml_expected_returns, \n",
    "        ml_blend_ratio=ml_blend_ratio\n",
    "    ),\n",
    "    \n",
    "    'ML-Enhanced (Conservative)': create_ml_enhanced_strategy(\n",
    "        ml_expected_returns,\n",
    "        ml_blend_ratio=0.4  # More conservative: 40% ML, 60% historical\n",
    "    ),\n",
    "    \n",
    "    'ML-Enhanced (Aggressive)': create_ml_enhanced_strategy(\n",
    "        ml_expected_returns,\n",
    "        ml_blend_ratio=0.8  # More aggressive: 80% ML, 20% historical\n",
    "    )\n",
    "}\n",
    "\n",
    "# Run backtests with realistic transaction costs\n",
    "transaction_cost = 0.001  # 10 basis points\n",
    "backtest_results = {}\n",
    "\n",
    "# Use last 3 years of data for backtesting\n",
    "test_data = prices.tail(252 * 3)\n",
    "\n",
    "print(f\"\\nBacktesting period: {test_data.index[0].strftime('%Y-%m-%d')} to {test_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Transaction cost: {transaction_cost*100:.1f}%\")\n",
    "print(f\"\\nRunning backtests...\")\n",
    "\n",
    "for strategy_name, strategy_func in strategies_to_compare.items():\n",
    "    print(f\"\\n  Testing {strategy_name}...\", end='')\n",
    "    \n",
    "    config = BacktestConfig(\n",
    "        initial_capital=100000,\n",
    "        transaction_cost_pct=transaction_cost,\n",
    "        rebalance_frequency=RebalanceFrequency.MONTHLY\n",
    "    )\n",
    "    \n",
    "    engine = BacktestEngine(config)\n",
    "    \n",
    "    try:\n",
    "        results = engine.run_backtest(test_data, strategy_func)\n",
    "        \n",
    "        # Calculate key metrics\n",
    "        returns = results.returns\n",
    "        annual_return = returns.mean() * 252\n",
    "        volatility = returns.std() * np.sqrt(252)\n",
    "        sharpe = (annual_return - 0.02) / volatility if volatility > 0 else 0\n",
    "        \n",
    "        # Calculate max drawdown\n",
    "        cum_returns = (1 + returns).cumprod()\n",
    "        running_max = cum_returns.expanding().max()\n",
    "        drawdown = (cum_returns - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        backtest_results[strategy_name] = {\n",
    "            'annual_return': annual_return,\n",
    "            'volatility': volatility,\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'total_costs': results.total_transaction_costs,\n",
    "            'final_value': results.portfolio_values.iloc[-1],\n",
    "            'cumulative_returns': cum_returns\n",
    "        }\n",
    "        \n",
    "        print(f\" ✓ Sharpe: {sharpe:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" ✗ Failed: {str(e)}\")\n",
    "        backtest_results[strategy_name] = {\n",
    "            'annual_return': np.nan,\n",
    "            'volatility': np.nan,\n",
    "            'sharpe_ratio': np.nan,\n",
    "            'max_drawdown': np.nan,\n",
    "            'total_costs': np.nan,\n",
    "            'final_value': np.nan,\n",
    "            'cumulative_returns': pd.Series()\n",
    "        }\n",
    "\n",
    "# Create comprehensive comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Cumulative Returns', 'Risk-Return Profile', \n",
    "                   'Sharpe Ratios', 'Max Drawdown'),\n",
    "    specs=[[{'type': 'scatter'}, {'type': 'scatter'}],\n",
    "           [{'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "# Define colors for each strategy\n",
    "colors = {\n",
    "    'Traditional Max Sharpe': 'blue',\n",
    "    'ML-Enhanced (Loaded)': 'green',\n",
    "    'ML-Enhanced (Conservative)': 'orange',\n",
    "    'ML-Enhanced (Aggressive)': 'red'\n",
    "}\n",
    "\n",
    "# 1. Cumulative returns\n",
    "for strategy_name, metrics in backtest_results.items():\n",
    "    if len(metrics['cumulative_returns']) > 0:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=metrics['cumulative_returns'].index,\n",
    "                y=(metrics['cumulative_returns'] - 1) * 100,\n",
    "                mode='lines',\n",
    "                name=strategy_name,\n",
    "                line=dict(width=2, color=colors.get(strategy_name))\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "# 2. Risk-return scatter (WITHOUT text labels)\n",
    "strategy_names = list(backtest_results.keys())\n",
    "returns = [backtest_results[s]['annual_return'] * 100 for s in strategy_names]\n",
    "volatilities = [backtest_results[s]['volatility'] * 100 for s in strategy_names]\n",
    "sharpes = [backtest_results[s]['sharpe_ratio'] for s in strategy_names]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=volatilities,\n",
    "        y=returns,\n",
    "        mode='markers',  # Removed 'text' from mode\n",
    "        marker=dict(\n",
    "            size=15, \n",
    "            color=[colors.get(s, 'gray') for s in strategy_names],\n",
    "            line=dict(width=2, color='black')\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Sharpe ratios comparison\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=strategy_names,\n",
    "        y=sharpes,\n",
    "        marker_color=[colors.get(s, 'gray') for s in strategy_names],\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Max Drawdown\n",
    "max_drawdowns = [backtest_results[s]['max_drawdown'] * 100 for s in strategy_names]\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=strategy_names,\n",
    "        y=max_drawdowns,\n",
    "        marker_color=[colors.get(s, 'gray') for s in strategy_names],\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(title_text=\"\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Cumulative Return (%)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Annual Return (%)\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Annual Volatility (%)\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Sharpe Ratio\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Max Drawdown (%)\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000, \n",
    "    showlegend=True, \n",
    "    title_text='ML-Enhanced vs Traditional Strategy Comparison<br>(Using Loaded ML Predictions)',\n",
    "    margin=dict(b=150)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Strategy':<30} {'Return':<10} {'Vol':<10} {'Sharpe':<10} {'MaxDD':<10} {'Costs':<10}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for strategy, metrics in backtest_results.items():\n",
    "    if not np.isnan(metrics['annual_return']):\n",
    "        print(f\"{strategy:<30} \"\n",
    "              f\"{metrics['annual_return']*100:>8.1f}% \"\n",
    "              f\"{metrics['volatility']*100:>8.1f}% \"\n",
    "              f\"{metrics['sharpe_ratio']:>9.2f} \"\n",
    "              f\"{metrics['max_drawdown']*100:>8.1f}% \"\n",
    "              f\"${metrics['total_costs']:>8.0f}\")\n",
    "\n",
    "# Compare to ML notebook results (with error handling)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION AGAINST ML NOTEBOOK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check what keys are actually available in ml_results\n",
    "if 'model_performance' in ml_results:\n",
    "    print(f\"ML Notebook reported improvement: {ml_results['model_performance']['improvement_pct']:.1f}%\")\n",
    "else:\n",
    "    print(\"Note: 'model_performance' key not found in ML results\")\n",
    "    print(\"Available keys:\", list(ml_results.keys()))\n",
    "    \n",
    "    # Try to calculate improvement from available data\n",
    "    if 'walk_forward_stats' in ml_results:\n",
    "        print(f\"ML Notebook walk-forward avg Sharpe: {ml_results['walk_forward_stats']['average_sharpe']:.3f}\")\n",
    "\n",
    "# Calculate backtest improvement\n",
    "ml_enhanced_sharpe = backtest_results['ML-Enhanced (Loaded)']['sharpe_ratio']\n",
    "traditional_sharpe = backtest_results['Traditional Max Sharpe']['sharpe_ratio']\n",
    "backtest_improvement = (ml_enhanced_sharpe - traditional_sharpe) / traditional_sharpe * 100\n",
    "\n",
    "print(f\"\\nBacktest Results:\")\n",
    "print(f\"Traditional Sharpe: {traditional_sharpe:.3f}\")\n",
    "print(f\"ML-Enhanced Sharpe: {ml_enhanced_sharpe:.3f}\")\n",
    "print(f\"Improvement: {backtest_improvement:.1f}%\")\n",
    "\n",
    "# Performance breakdown\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ML STRATEGY SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "conservative_sharpe = backtest_results['ML-Enhanced (Conservative)']['sharpe_ratio']\n",
    "aggressive_sharpe = backtest_results['ML-Enhanced (Aggressive)']['sharpe_ratio']\n",
    "\n",
    "print(f\"Conservative (40% ML): Sharpe = {conservative_sharpe:.3f}\")\n",
    "print(f\"Standard (60% ML):     Sharpe = {ml_enhanced_sharpe:.3f}\")\n",
    "print(f\"Aggressive (80% ML):   Sharpe = {aggressive_sharpe:.3f}\")\n",
    "print(f\"\\nOptimal blend appears to be around {ml_blend_ratio*100:.0f}% ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Market regime analysis requires period-specific ML model training\n",
    "# which is computationally intensive. The walk-forward validation in the \n",
    "# ML notebook (06_ml_price_prediction.ipynb) already demonstrates \n",
    "# out-of-sample performance across different time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways from Backtesting Analysis\n",
    "\n",
    "### 1. **Transaction Costs Matter**\n",
    "- Even small transaction costs (0.1%) significantly impact returns\n",
    "- Daily rebalancing is almost never optimal due to costs\n",
    "- Monthly or quarterly rebalancing typically provides the best balance\n",
    "\n",
    "### 2. **Strategy Performance Varies by Market Regime**\n",
    "- Max Sharpe performs well in trending markets\n",
    "- Min Volatility shines during market stress\n",
    "- No single strategy dominates in all conditions\n",
    "\n",
    "### 3. **Monte Carlo Results Show Robustness**\n",
    "- Positive expected returns across most scenarios\n",
    "- Risk of significant drawdowns exists (~20-30%)\n",
    "- Sharpe ratios are generally positive but variable\n",
    "\n",
    "### 4. **Optimal Rebalancing Frequency**\n",
    "- Monthly or quarterly rebalancing is usually optimal\n",
    "- Must balance tracking error vs transaction costs\n",
    "- Consider market volatility when choosing frequency\n",
    "\n",
    "### 5. **Weight Stability**\n",
    "- Optimal weights can change significantly month-to-month\n",
    "- Consider using weight bounds or smoothing\n",
    "- More stable strategies may have lower turnover costs\n",
    "\n",
    "## Next Steps\n",
    "- Implement regime detection to switch strategies\n",
    "- Test more sophisticated rebalancing rules\n",
    "- Add stop-loss or drawdown controls\n",
    "- Consider factor-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
